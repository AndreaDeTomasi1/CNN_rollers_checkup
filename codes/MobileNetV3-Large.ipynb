import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
import glob
import random
import os
import cv2
from tqdm import tqdm
import numpy as np
from PIL import Image, ImageOps
import timm
import pandas as pd
from sklearn.model_selection import KFold

# ---- 1) Cartella dataset ----
source_dir = './ruote_catalogate_def/'  # aggiorna se necessario

# ---- 2) Funzione per caricare percorsi e label ----
def load_image_paths_and_labels(base_dir):
    if not os.path.exists(base_dir):
        raise FileNotFoundError(f"La cartella {base_dir} non esiste!")
    
    classes = sorted(os.listdir(base_dir))
    image_paths = []
    labels = []

    for cls in classes:
        cls_path = os.path.join(base_dir, cls)
        if cls.startswith('.') or not os.path.isdir(cls_path):
            continue
        try:
            x, y = cls.split(',')
        except:
            continue
        label = (int(x)/3, int(y)/3)

        for img_file in glob.glob(os.path.join(cls_path, '*.*')):
            image_paths.append(img_file)
            labels.append(label)

    return image_paths, labels

# ---- 4) Dataset personalizzato ----
class WheelDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None, edge_transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform
        self.edge_transform = edge_transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = cv2.imread(self.image_paths[idx])
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Edge detection
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 30, 90)
        edges_rgb = np.stack([edges]*3, axis=-1)

        img = Image.fromarray(img)
        img = ImageOps.exif_transpose(img)
        edges_rgb = Image.fromarray(edges_rgb)
        edges_rgb = ImageOps.exif_transpose(edges_rgb)

        if self.transform:
            img = self.transform(img)
        if self.edge_transform:
            edges_rgb = self.edge_transform(edges_rgb)

        combined = torch.cat((img, edges_rgb), dim=0)
        label = torch.tensor(self.labels[idx], dtype=torch.float32)
        return combined, label

# ---- 5) Trasformazioni ----
class CenterPadCrop:
    def __init__(self, final_size=224):
        self.final_size = final_size

    def __call__(self, img: Image.Image):
        w, h = img.size
        if h > w:
            new_h = self.final_size
            new_w = int(w * self.final_size / h)
        else:
            new_w = self.final_size
            new_h = int(h * self.final_size / w)
        img = img.resize((new_w, new_h), resample=Image.BILINEAR)

        pad_left = (self.final_size - new_w) // 2
        pad_right = self.final_size - new_w - pad_left
        pad_top = (self.final_size - new_h) // 2
        pad_bottom = self.final_size - new_h - pad_top

        img = transforms.functional.pad(img, padding=(pad_left, pad_top, pad_right, pad_bottom), fill=0)
        return img

transform_rgb = transforms.Compose([
    CenterPadCrop(final_size=224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])

edge_transform = transforms.Compose([
    CenterPadCrop(final_size=224),
    transforms.ToTensor(),
])

all_paths, all_labels = load_image_paths_and_labels(source_dir)

k_folds = 5  # numero di fold
kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

fold_index = 1
for train_index, test_index in kf.split(all_paths):

    print(f"\n\n======================")
    print(f"     FOLD {fold_index}/{k_folds}")
    print(f"======================\n")

    # ---- Split del fold ----
    train_paths  = [all_paths[i] for i in train_index]
    train_labels = [all_labels[i] for i in train_index]
    test_paths   = [all_paths[i] for i in test_index]
    test_labels  = [all_labels[i] for i in test_index]

    # ---- Dataset e DataLoader ----
    train_dataset = WheelDataset(train_paths, train_labels, transform=transform_rgb, edge_transform=edge_transform)
    test_dataset  = WheelDataset(test_paths, test_labels, transform=transform_rgb, edge_transform=edge_transform)

    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)
    test_loader  = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)

    # ---- CREA NUOVO MODELLO PER OGNI FOLD ----
    base = timm.create_model('mobilenetv3_large_100', pretrained=True)

    # Primo conv → 6 canali
    orig_conv = base.conv_stem
    base.conv_stem = nn.Conv2d(
        in_channels=6,
        out_channels=orig_conv.out_channels,
        kernel_size=orig_conv.kernel_size,
        stride=orig_conv.stride,
        padding=orig_conv.padding,
        bias=orig_conv.bias is not None
    )
    with torch.no_grad():
        base.conv_stem.weight[:, :3] = orig_conv.weight
        base.conv_stem.weight[:, 3:] = orig_conv.weight

    in_features = base.classifier.in_features
    base.classifier = nn.Linear(in_features, 2)

    class MobileNetV3Regressor(nn.Module):
        def __init__(self, base_model):
            super().__init__()
            self.base = base_model
        def forward(self, x):
            x = self.base(x)
            return torch.sigmoid(x)

    model = MobileNetV3Regressor(base).to(device)

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)

    # Tracking migliori risultati
    best_overall = {"mse": float("inf"), "results": None, "epoch": None}
    best_under_5 = {"mse": float("inf"), "results": None, "epoch": None}
    best_under_10 = {"mse": float("inf"), "results": None, "epoch": None}

    num_epochs = 40

    # =======================
    #      TRAINING LOOP
    # =======================
    for epoch in range(num_epochs):

        # ----- TRAIN -----
        model.train()
        running_loss = 0.0

        for inputs, labels in tqdm(train_loader, desc=f"[FOLD {fold_index}] Epoch {epoch+1}/{num_epochs} - Training"):
            inputs, labels = inputs.to(device), labels.float().to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)

        train_loss = running_loss / len(train_dataset)
        print(f"[FOLD {fold_index}] Epoch {epoch+1} - Train MSE: {train_loss:.4f}")

        # ----- TEST -----
        model.eval()
        running_loss_test = 0.0
        epoch_results = []

        with torch.no_grad():
            for idx, (inputs, labels) in enumerate(tqdm(test_loader, desc=f"[FOLD {fold_index}] Epoch {epoch+1}/{num_epochs} - Testing")):
                inputs, labels = inputs.to(device), labels.float().to(device)
                outputs = model(inputs)

                pred_x, pred_y = outputs[0].cpu().numpy()
                real_x, real_y = labels[0].cpu().numpy()

                loss = criterion(outputs, labels)
                running_loss_test += loss.item()

                epoch_results.append({
                    "path": test_paths[idx],
                    "x_pred": float(pred_x),
                    "y_pred": float(pred_y),
                    "x_real": float(real_x),
                    "y_real": float(real_y),
                })

        test_loss = running_loss_test / len(test_dataset)
        gap = abs(test_loss - train_loss) / train_loss * 100

        print(f"[FOLD {fold_index}] Test MSE: {test_loss:.4f}  | GAP% = {gap:.2f}%")

        # ---- SALVATAGGI ----

        # BEST OVERALL
        if test_loss < best_overall["mse"]:
            best_overall.update({"mse": test_loss, "results": epoch_results.copy(), "epoch": epoch})
            torch.save(model.state_dict(), f"fold_{fold_index}_best_overall.pth")
            pd.DataFrame(epoch_results).to_csv(f"fold_{fold_index}_best_overall.csv", index=False)

        # BEST GAP <5%
        if gap < 5 and test_loss < best_under_5["mse"]:
            best_under_5.update({"mse": test_loss, "results": epoch_results.copy(), "epoch": epoch})
            torch.save(model.state_dict(), f"fold_{fold_index}_best_under_5.pth")
            pd.DataFrame(epoch_results).to_csv(f"fold_{fold_index}_best_under_5.csv", index=False)

        # BEST GAP <10%
        if gap < 10 and test_loss < best_under_10["mse"]:
            best_under_10.update({"mse": test_loss, "results": epoch_results.copy(), "epoch": epoch})
            torch.save(model.state_dict(), f"fold_{fold_index}_best_under_10.pth")
            pd.DataFrame(epoch_results).to_csv(f"fold_{fold_index}_best_under_10.csv", index=False)

    # Fine fold → salva report riepilogativo
    df = pd.DataFrame({
        "best_overall": [best_overall["mse"]],
        "best_under_5": [best_under_5["mse"]],
        "best_under_10": [best_under_10["mse"]],
    })
    df.to_csv(f"fold_{fold_index}_summary.csv", index=False)

    fold_index += 1

print("\n\n============ FINITO TUTTO IL K-FOLD ============\n")
